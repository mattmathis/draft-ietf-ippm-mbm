      <section anchor="models" title="Common Model Calculations">

        <t>The Target Transport Performance is used to derive the
        target_window_size and the reference target_run_length.</t>

        <t>The target_window_size, is the average window size in
        packets needed to meet the target_rate, for the specified
        target_RTT and target_MTU. It is given by:</t>

        <t>target_window_size = ceiling( target_rate * target_RTT /
        ( target_MTU - header_overhead ) )</t>

        <t>Target_run_length is an estimate of the minimum required
        number of unmarked packets that must be delivered between
        losses or ECN Congestion Experienced (CE) marks, as
        computed by a mathematical model of TCP congestion control.
        The derivation here follows 
        <xref target="MSMO97" />, and by design is quite
        conservative.</t>

        <t>Reference target_run_length is derived as follows:
        assume the subpath_IP_capacity is infinitesimally larger
        than the target_data_rate plus the required
        header_overhead. Then target_window_size also predicts the
        onset of queueing. A larger window will cause a standing
        queue at the bottleneck.</t>

        <t>Assume the transport protocol is using standard Reno
        style Additive Increase, Multiplicative Decrease (AIMD)
        congestion control 
        <xref target="RFC5681" /> (but not Appropriate Byte Counting
        
        <xref target="RFC3465" />) and the receiver is using
        standard delayed ACKs. Reno increases the window by one
        packet every pipe_size worth of ACKs. With delayed ACKs
        this takes 2 Round Trip Times per increase. To exactly fill
        the pipe, losses must be no closer than when the peak of
        the AIMD sawtooth reached exactly twice the
        target_window_size otherwise the multiplicative window
        reduction triggered by the loss would cause the network to
        be underfilled. Following 
        <xref target="MSMO97" /> the number of packets between
        losses must be the area under the AIMD sawtooth. They must
        be no more frequent than every 1 in
        ((3/2)*target_window_size)*(2*target_window_size) packets,
        which simplifies to:</t>

        <t>target_run_length = 3*(target_window_size^2)</t>

        <t>Note that this calculation is very conservative and is
        based on a number of assumptions that may not apply. 
        <xref target="derive" /> discusses these assumptions and
        provides some alternative models. If a different model is
        used, a fully specified TIDS or FSTIDS MUST document the
        actual method for computing target_run_length and ratio
        between alternate target_run_length and the reference
        target_run_length calculated above, along with a discussion
        of the rationale for the underlying assumptions.</t>

        <t>These two parameters, target_window_size and
        target_run_length, directly imply most of the individual
        parameters for the tests in 
        <xref target="tests" />.</t>
      </section>
      <section anchor="derate" title="Parameter Derating">

        <t>Since some aspects of the models are very conservative,
        the MBM framework permits some latitude in derating test
        parameters. Rather than trying to formalize more
        complicated models we permit some test parameters to be
        relaxed as long as they meet some additional procedural
        constraints: 
        <list style="symbols">

          <t>The TIDS or FSTIDS MUST document and justify the
          actual method used to compute the derated metric
          parameters.</t>

          <t>The validation procedures described in 
          <xref target="validation" /> must be used to demonstrate
          the feasibility of meeting the Target Transport
          Performance with infrastructure that infinitesimally
          passes the derated tests.</t>

          <t>The validation process for a FSTIDS itself must be
          documented is such a way that other researchers can
          duplicate the validation experiments.</t>
        </list></t>

        <t>Except as noted, all tests below assume no derating.
        Tests where there is not currently a well established model
        for the required parameters explicitly include derating as
        a way to indicate flexibility in the parameters.</t>
      </section>
